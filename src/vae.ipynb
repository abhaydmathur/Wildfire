{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import copy\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading meta file: /data/amathur-23/ROB313/train_unlabeled.csv\n",
      "Loading meta file: /data/amathur-23/ROB313/train.csv\n",
      "Loading meta file: /data/amathur-23/ROB313/val.csv\n",
      "Loading meta file: /data/amathur-23/ROB313/test.csv\n"
     ]
    }
   ],
   "source": [
    "from utils.datasets import WildfireDataset\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_dataset = WildfireDataset('/data/amathur-23/ROB313', split='train', labeled=False, transforms=transform)\n",
    "data_train_labeled = WildfireDataset('/data/amathur-23/ROB313', split='train', labeled=True, transforms=transform)\n",
    "val_dataset = WildfireDataset('/data/amathur-23/ROB313', split='val', transforms=transform)\n",
    "test_dataset = WildfireDataset('/data/amathur-23/ROB313', split='test', transforms=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_loader_labeled = DataLoader(data_train_labeled, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvVAE(nn.Module):\n",
    "    def __init__(self, latent_dim=128):\n",
    "        super(ConvVAE, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        # 3x224x224\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 4, stride=2, padding=1), # 224 -> 112\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 4, stride=2, padding=1), # 112 -> 56\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1), # 56 -> 28\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, 4, stride=2, padding=1),  # 28 -> 14\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, 4, stride=2, padding=1),  # 14 -> 7\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.encoder_output_dim = (256 * 7 * 7)\n",
    "        self.fc_mu = nn.Linear(self.encoder_output_dim, latent_dim)\n",
    "        self.fc_var = nn.Linear(self.encoder_output_dim, latent_dim)\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder_input = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.Linear(256, self.encoder_output_dim)\n",
    "        ) \n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 256, 4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 3, 4, stride=2, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def encode(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(batch_size,-1)\n",
    "        mu = self.fc_mu(x)\n",
    "        log_var = self.fc_var(x)\n",
    "        return mu, log_var\n",
    "    \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def decode(self, z):\n",
    "        x = self.decoder_input(z)\n",
    "        x = x.view(x.size(0), 256, 7, 7) \n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        z = self.decode(z)\n",
    "        return z, mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BetaVAELoss(nn.Module):\n",
    "    def __init__(self, beta=1):\n",
    "        super(BetaVAELoss, self).__init__()\n",
    "        self.beta = beta\n",
    "        \n",
    "    def forward(self, x, recon_x, mu, logvar):\n",
    "        recon_loss = F.mse_loss(recon_x, x, reduction='sum')\n",
    "        kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        return recon_loss + self.beta * kl_loss\n",
    "    \n",
    "criterion_vae = BetaVAELoss(beta=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train(model, dataloader, optimizer, device, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(dataloader, f\"Training {epoch}\"):\n",
    "        data = batch['image'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = criterion_vae(data, recon_batch, mu, logvar)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader.dataset)\n",
    "\n",
    "# Validation Function\n",
    "def validate(model, dataloader, device, epoch):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, f\"Validation {epoch}\"):\n",
    "            data = batch['image'].to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            loss = criterion_vae(data, recon_batch, mu, logvar)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 256\n",
    "learning_rate = 1e-5\n",
    "num_epochs = 50\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ConvVAE(latent_dim=latent_dim).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "# for epoch in range(num_epochs):\n",
    "#     train_loss = train(model, train_loader, optimizer, device, epoch)\n",
    "#     print(f\"Epoch {epoch} Train loss: {train_loss}\")\n",
    "#     val_loss = validate(model, val_loader, device, epoch)\n",
    "#     print(f\"Epoch {epoch} Validation loss: {val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "def perform_clustering(features, method=\"kmeans\", num_clusters=2):\n",
    "    if method == \"kmeans\":\n",
    "        clustering = KMeans(n_clusters=num_clusters, random_state=42).fit(features)\n",
    "    elif method == \"gmm\":\n",
    "        clustering = GaussianMixture(n_components=num_clusters, random_state=42).fit(features)\n",
    "    elif method == \"dbscan\":\n",
    "        clustering = DBSCAN(eps=0.5, min_samples=5).fit(features)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported clustering method\")\n",
    "    return clustering.labels_\n",
    "\n",
    "\n",
    "# labels = perform_clustering(labelled_features, method=\"kmeans\", num_clusters=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, device, input_dim=128, dropout=0.3):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.device = device\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        ) \n",
    "\n",
    "    def forward(self, x): \n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def train_classifier(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        target = batch['label'].float().to(device)  \n",
    "        image = batch['image'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image).squeeze()  \n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        predicted = (output > 0.5).float() \n",
    "        correct += (predicted == target).sum().item()\n",
    "        total += target.size(0)\n",
    "\n",
    "    accuracy = 100. * correct / total\n",
    "    return total_loss / len(train_loader), accuracy\n",
    "\n",
    "def validate_classifier(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            target = batch['label'].float().to(device)\n",
    "            image = batch['image'].to(device)\n",
    "            output = model(image).squeeze()\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            predicted = (output > 0.5).float()  \n",
    "            correct += (predicted == target).sum().item()\n",
    "            total += target.size(0)\n",
    "            all_preds.append(predicted.cpu().numpy())\n",
    "            all_targets.append(target.cpu().numpy())\n",
    "            \n",
    "        f1 = f1_score(np.concatenate(all_targets), np.concatenate(all_preds))\n",
    "        print(f'Validation Loss: {total_loss / len(val_loader)}')\n",
    "        print(f'Validation Accuracy: {100. * correct / total}')\n",
    "        print(f'Validation F1 Score: {f1}')\n",
    "        return total_loss / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(model, dataloader, device, labels = True):\n",
    "    model.eval()\n",
    "    all_features = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            data = batch['image'].to(device)\n",
    "            target = batch['label'].float().to(device) if labels else None\n",
    "            mu, _ = model.encode(data)\n",
    "            all_features.append(mu.cpu().numpy())\n",
    "            all_targets.append(target.cpu().numpy()) if labels else None\n",
    "    if labels:\n",
    "        return np.concatenate(all_features), np.concatenate(all_targets)\n",
    "    return np.concatenate(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvVAE(latent_dim=latent_dim).to(device)\n",
    "model.load_state_dict(torch.load('/data/iivanova-23/ROB313/models/vae_trial_256_32/vae_model.pth'))\n",
    "\n",
    "features = extract_features(model, train_loader, device, labels=False)\n",
    "labels = perform_clustering(features, method=\"kmeans\", num_clusters=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_labeled , labels_labeled = extract_features(model, train_loader_labeled, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, ConcatDataset\n",
    "dataset_custom_labeled = TensorDataset(torch.tensor(features_labeled, dtype=torch.float32), torch.tensor(labels_labeled, dtype=torch.float16))\n",
    "dataset_custom_labeled = [{'image': data[0], 'label': data[1]} for data in dataset_custom_labeled]\n",
    "\n",
    "dataset_custom = TensorDataset(torch.tensor(features, dtype=torch.float32), torch.tensor(labels, dtype=torch.float16))\n",
    "dataset_custom = [{'image': data[0], 'label': data[1]} for data in dataset_custom]\n",
    "data_loader_custom = DataLoader(dataset_custom, batch_size=32, shuffle=True)\n",
    "data_concat = ConcatDataset([dataset_custom, dataset_custom_labeled])\n",
    "dataloader_concat = DataLoader(data_concat, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Train loss: 0.1332712373223715, Train accuracy: 99.89751727329829\n",
      "Epoch 1 Train loss: 0.002169514353253906, Train accuracy: 99.99669410559027\n",
      "Epoch 2 Train loss: 0.0007827290197733217, Train accuracy: 99.99669410559027\n",
      "Epoch 3 Train loss: 0.00034756931304025544, Train accuracy: 99.99669410559027\n",
      "Epoch 4 Train loss: 0.0002354165494474474, Train accuracy: 99.99669410559027\n",
      "Epoch 5 Train loss: 0.00016497059153923856, Train accuracy: 99.99669410559027\n",
      "Epoch 6 Train loss: 7.544487934230643e-05, Train accuracy: 99.99669410559027\n",
      "Epoch 7 Train loss: 5.33828404595009e-05, Train accuracy: 99.99669410559027\n",
      "Epoch 8 Train loss: 7.363406701394292e-05, Train accuracy: 99.99669410559027\n",
      "Epoch 9 Train loss: 4.004760178255151e-05, Train accuracy: 99.99669410559027\n",
      "Epoch 10 Train loss: 7.698080554708315e-05, Train accuracy: 99.99669410559027\n",
      "Epoch 11 Train loss: 3.884299838757903e-05, Train accuracy: 99.99669410559027\n",
      "Epoch 12 Train loss: 5.099662315680664e-05, Train accuracy: 99.99669410559027\n",
      "Epoch 13 Train loss: 4.617956139451939e-05, Train accuracy: 99.99669410559027\n",
      "Epoch 14 Train loss: 3.2709310577664635e-05, Train accuracy: 99.99669410559027\n",
      "Epoch 15 Train loss: 3.5038210376645906e-05, Train accuracy: 99.99669410559027\n",
      "Epoch 16 Train loss: 3.375381696328866e-05, Train accuracy: 99.99669410559027\n",
      "Epoch 17 Train loss: 5.626438696745422e-05, Train accuracy: 99.99669410559027\n",
      "Epoch 18 Train loss: 3.025451404527387e-05, Train accuracy: 99.99669410559027\n",
      "Epoch 19 Train loss: 3.3446294619747955e-05, Train accuracy: 99.99669410559027\n"
     ]
    }
   ],
   "source": [
    "classifier = Classifier(device, input_dim=256).to(device)\n",
    "optimizer_classifier = optim.Adam(classifier.parameters(), lr=1e-4)\n",
    "criterion_classifier = nn.BCELoss()\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_accuracy = train_classifier(classifier, data_loader_custom, optimizer_classifier, criterion_classifier, device)\n",
    "    print(f\"Epoch {epoch} Train loss: {train_loss}, Train accuracy: {train_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 43.41704363822937\n",
      "Validation Accuracy: 54.285714285714285\n",
      "Validation F1 Score: 0.7037037037037037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "43.41704363822937"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features_labeled , labels_labeled = extract_features(model, val_loader, device)\n",
    "# dataset_custom = TensorDataset(torch.tensor(features_labeled, dtype=torch.float32), torch.tensor(labels_labeled, dtype=torch.float16))\n",
    "# dataset_custom = [{'image': data[0], 'label': data[1]} for data in dataset_custom]\n",
    "# val_loader = DataLoader(dataset_custom, batch_size=32, shuffle=True)\n",
    "validate_classifier(classifier, val_loader, nn.BCELoss(), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 42.491321641176484\n",
      "Validation Accuracy: 55.2309890458803\n",
      "Validation F1 Score: 0.711597463694007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42.491321641176484"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features_labeled , labels_labeled = extract_features(model, test_loader, device)\n",
    "# dataset_custom = TensorDataset(torch.tensor(features_labeled, dtype=torch.float32), torch.tensor(labels_labeled, dtype=torch.float16))\n",
    "# dataset_custom = [{'image': data[0], 'label': data[1]} for data in dataset_custom]\n",
    "# test_loader = DataLoader(dataset_custom, batch_size=32, shuffle=True)\n",
    "\n",
    "validate_classifier(classifier, test_loader, nn.BCELoss(), device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".rob313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
