{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import copy\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from typing import List, Callable, Union, Any, TypeVar, Tuple\n",
    "\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorQuantizer(nn.Module):\n",
    "    \"\"\"\n",
    "    Reference:\n",
    "    [1] https://github.com/deepmind/sonnet/blob/v2/sonnet/src/nets/vqvae.py\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 num_embeddings: int,\n",
    "                 embedding_dim: int,\n",
    "                 beta: float = 0.25):\n",
    "        super(VectorQuantizer, self).__init__()\n",
    "        self.K = num_embeddings\n",
    "        self.D = embedding_dim\n",
    "        self.beta = beta\n",
    "\n",
    "        self.embedding = nn.Embedding(self.K, self.D)\n",
    "        self.embedding.weight.data.uniform_(-1 / self.K, 1 / self.K)\n",
    "\n",
    "    def forward(self, latents: torch.Tensor) -> torch.Tensor:\n",
    "        latents = latents.permute(0, 2, 3, 1).contiguous()  # [B x D x H x W] -> [B x H x W x D]\n",
    "        latents_shape = latents.shape\n",
    "        flat_latents = latents.view(-1, self.D)  # [BHW x D]\n",
    "\n",
    "        # Compute L2 distance between latents and embedding weights\n",
    "        dist = torch.sum(flat_latents ** 2, dim=1, keepdim=True) + \\\n",
    "               torch.sum(self.embedding.weight ** 2, dim=1) - \\\n",
    "               2 * torch.matmul(flat_latents, self.embedding.weight.t())  # [BHW x K]\n",
    "\n",
    "        # Get the encoding that has the min distance\n",
    "        encoding_inds = torch.argmin(dist, dim=1).unsqueeze(1)  # [BHW, 1]\n",
    "\n",
    "        # Convert to one-hot encodings\n",
    "        device = latents.device\n",
    "        encoding_one_hot = torch.zeros(encoding_inds.size(0), self.K, device=device)\n",
    "        encoding_one_hot.scatter_(1, encoding_inds, 1)  # [BHW x K]\n",
    "\n",
    "        # Quantize the latents\n",
    "        quantized_latents = torch.matmul(encoding_one_hot, self.embedding.weight)  # [BHW, D]\n",
    "        quantized_latents = quantized_latents.view(latents_shape)  # [B x H x W x D]\n",
    "\n",
    "        # Compute the VQ Losses\n",
    "        commitment_loss = F.mse_loss(quantized_latents.detach(), latents)\n",
    "        embedding_loss = F.mse_loss(quantized_latents, latents.detach())\n",
    "\n",
    "        vq_loss = commitment_loss * self.beta + embedding_loss\n",
    "\n",
    "        # Add the residue back to the latents\n",
    "        quantized_latents = latents + (quantized_latents - latents).detach()\n",
    "\n",
    "        return quantized_latents.permute(0, 3, 1, 2).contiguous(), vq_loss  # [B x D x H x W]\n",
    "\n",
    "class ResidualLayer(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int):\n",
    "        super(ResidualLayer, self).__init__()\n",
    "        self.resblock = nn.Sequential(nn.Conv2d(in_channels, out_channels,\n",
    "                                                kernel_size=3, padding=1, bias=False),\n",
    "                                      nn.ReLU(True),\n",
    "                                      nn.Conv2d(out_channels, out_channels,\n",
    "                                                kernel_size=1, bias=False))\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        return input + self.resblock(input)\n",
    "\n",
    "\n",
    "class VQVAE(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 embedding_dim: int,\n",
    "                 num_embeddings: int,\n",
    "                 hidden_dims: List = None,\n",
    "                 beta: float = 0.25,\n",
    "                 pretrained: bool = False,\n",
    "                 **kwargs) -> None:\n",
    "        super(VQVAE, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.beta = beta\n",
    "        self.pretrained = pretrained\n",
    "        \n",
    "        # Resnet Encoder\n",
    "        if self.pretrained:\n",
    "            resnet = models.resnet50(weights=\"DEFAULT\")\n",
    "            modules = list(resnet.children())[:-1]\n",
    "            self.resnet = nn.Sequential(*modules)\n",
    "            in_channels = 2048\n",
    "            \n",
    "        modules = []\n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [128, 256]\n",
    "\n",
    "        # Build Encoder\n",
    "        for h_dim in hidden_dims:\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(in_channels, out_channels=h_dim,\n",
    "                              kernel_size=3, stride=1, padding=1),\n",
    "                    nn.LeakyReLU())\n",
    "            )\n",
    "            in_channels = h_dim\n",
    "\n",
    "        modules.append(\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(in_channels, in_channels,\n",
    "                          kernel_size=3, stride=1, padding=1),\n",
    "                nn.LeakyReLU())\n",
    "        )\n",
    "\n",
    "        for _ in range(6):\n",
    "            modules.append(ResidualLayer(in_channels, in_channels))\n",
    "        modules.append(nn.LeakyReLU())\n",
    "\n",
    "        modules.append(\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(in_channels, embedding_dim,\n",
    "                          kernel_size=1, stride=1),\n",
    "                nn.LeakyReLU())\n",
    "        )\n",
    "\n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "\n",
    "        self.vq_layer = VectorQuantizer(num_embeddings,\n",
    "                                        embedding_dim,\n",
    "                                        self.beta)\n",
    "\n",
    "        # Build Decoder\n",
    "        modules = []\n",
    "        modules.append(\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(embedding_dim,\n",
    "                          hidden_dims[-1],\n",
    "                          kernel_size=3,\n",
    "                          stride=1,\n",
    "                          padding=1),\n",
    "                nn.LeakyReLU())\n",
    "        )\n",
    "\n",
    "        for _ in range(6):\n",
    "            modules.append(ResidualLayer(hidden_dims[-1], hidden_dims[-1]))\n",
    "\n",
    "        modules.append(nn.LeakyReLU())\n",
    "\n",
    "        hidden_dims.reverse()\n",
    "\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.ConvTranspose2d(hidden_dims[i],\n",
    "                                       hidden_dims[i + 1],\n",
    "                                       kernel_size=4,\n",
    "                                       stride=2,\n",
    "                                       padding=1),\n",
    "                    nn.LeakyReLU())\n",
    "            )\n",
    "\n",
    "        modules.append(\n",
    "            nn.Sequential(\n",
    "            nn.ConvTranspose2d(hidden_dims[-1], hidden_dims[-1] // 2, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(hidden_dims[-1] // 2, out_channels=3, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()))\n",
    "        modules.append(nn.Upsample(size=(224, 224), mode='bilinear', align_corners=False))\n",
    "\n",
    "        self.decoder = nn.Sequential(*modules)\n",
    "\n",
    "    def encode(self, input: torch.Tensor) -> List[torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Encodes the input by passing through the encoder network\n",
    "        and returns the latent codes.\n",
    "        :param input: (Tensor) Input tensor to encoder [N x C x H x W]\n",
    "        :return: (Tensor) List of latent codes\n",
    "        \"\"\"\n",
    "        if self.pretrained:\n",
    "            input = self.resnet(input)\n",
    "        result = self.encoder(input)\n",
    "        return result\n",
    "\n",
    "    def decode(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Maps the given latent codes\n",
    "        onto the image space.\n",
    "        :param z: (Tensor) [B x D x H x W]\n",
    "        :return: (Tensor) [B x C x H x W]\n",
    "        \"\"\"\n",
    "\n",
    "        result = self.decoder(z)\n",
    "        return result\n",
    "\n",
    "    def forward(self, input: torch.Tensor, **kwargs) -> List[torch.Tensor]:\n",
    "        # input = input.to(next(self.parameters()).dtype)  # Ensure input type matches model parameters\n",
    "        # print(\"Input Shape:\", input.shape)\n",
    "        encoding = self.encode(input)\n",
    "        quantized_inputs, vq_loss = self.vq_layer(encoding)\n",
    "        z = self.decode(quantized_inputs)\n",
    "        return [z, input , vq_loss, quantized_inputs]\n",
    "\n",
    "    def loss_function(self,\n",
    "                      *args,\n",
    "                      **kwargs) -> dict:\n",
    "        \"\"\"\n",
    "        :param args:\n",
    "        :param kwargs:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        recons = args[0]\n",
    "        input = args[1]\n",
    "        vq_loss = args[2]\n",
    "        # print(\"Reconstructed Shape:\", recons.shape)\n",
    "        recons_loss = F.mse_loss(recons, input)\n",
    "        \n",
    "        loss = recons_loss + vq_loss\n",
    "        return {'loss': loss,\n",
    "                'Reconstruction_Loss': recons_loss,\n",
    "                'VQ_Loss':vq_loss}\n",
    "\n",
    "    def sample(self,\n",
    "               num_samples: int,\n",
    "               current_device: Union[int, str], **kwargs) -> torch.Tensor:\n",
    "        raise Warning('VQVAE sampler is not implemented.')\n",
    "\n",
    "    def generate(self, x: torch.Tensor, **kwargs) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Given an input image x, returns the reconstructed image\n",
    "        :param x: (Tensor) [B x C x H x W]\n",
    "        :return: (Tensor) [B x C x H x W]\n",
    "        \"\"\"\n",
    "\n",
    "        return self.forward(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.amp import autocast\n",
    "def train(model, dataloader, optimizer, device, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(dataloader, f\"Training {epoch}\"):\n",
    "        data = batch['image'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with autocast(\n",
    "            device_type=\"cuda\", dtype=torch.float16\n",
    "        ):\n",
    "            \n",
    "            args = model(data)\n",
    "            loss = model.loss_function(*args)['loss']\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader.dataset)\n",
    "\n",
    "# Validation Function\n",
    "def validate(model, dataloader, device, epoch):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, f\"Validation {epoch}\"):\n",
    "            data = batch['image'].to(device)\n",
    "            \n",
    "            with autocast(\n",
    "                device_type=\"cuda\", dtype=torch.float16\n",
    "            ):\n",
    "                args = model(data)\n",
    "                loss = model.loss_function(*args)['loss']\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading meta file: /data/amathur-23/ROB313/train_unlabeled.csv\n",
      "Loading meta file: /data/amathur-23/ROB313/train.csv\n",
      "Loading meta file: /data/amathur-23/ROB313/val.csv\n",
      "Loading meta file: /data/amathur-23/ROB313/test.csv\n"
     ]
    }
   ],
   "source": [
    "from utils.datasets import WildfireDataset\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_dataset = WildfireDataset('/data/amathur-23/ROB313', split='train', labeled=False, transforms=transform)\n",
    "data_train_labeled = WildfireDataset('/data/amathur-23/ROB313', split='train', labeled=True, transforms=transform)\n",
    "val_dataset = WildfireDataset('/data/amathur-23/ROB313', split='val', transforms=transform)\n",
    "test_dataset = WildfireDataset('/data/amathur-23/ROB313', split='test', transforms=transform)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "train_loader_labeled = DataLoader(data_train_labeled, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training 0: 100%|██████████| 946/946 [00:51<00:00, 18.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Train loss: 0.28576378948200065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation 0: 100%|██████████| 40/40 [00:01<00:00, 22.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Validation loss: 0.012841783866049752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training 1: 100%|██████████| 946/946 [00:52<00:00, 18.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Train loss: 0.014188698789037639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation 1: 100%|██████████| 40/40 [00:01<00:00, 23.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Validation loss: 0.0139276926243116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training 2: 100%|██████████| 946/946 [00:54<00:00, 17.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Train loss: 0.013792412497354202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation 2: 100%|██████████| 40/40 [00:01<00:00, 21.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Validation loss: 0.012901409963766734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = VQVAE(in_channels=3, embedding_dim=64, num_embeddings=512, hidden_dims=[128, 256], beta=0.25, pretrained=True)\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 3\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, train_loader, optimizer, device, epoch)\n",
    "    print(f\"Epoch {epoch} Train loss: {train_loss}\")\n",
    "    val_loss = validate(model, val_loader, device, epoch)\n",
    "    print(f\"Epoch {epoch} Validation loss: {val_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierFeatures_Coords(nn.Module):\n",
    "    def __init__(self, vae, input_dim=256, dropout=0.1):\n",
    "        super(ClassifierFeatures_Coords, self).__init__()\n",
    "        self.vae = vae\n",
    "        self.vae.eval()  \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, coords=None):\n",
    "        with torch.no_grad():\n",
    "            x = self.vae.encode(x)\n",
    "            x, _ = self.vae.vq_layer(x)\n",
    "        batch_size = x.shape[0]\n",
    "        x = x.view(batch_size, -1) \n",
    "        x = torch.cat((x, coords), dim=1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def train_classifier(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch in tqdm(train_loader):\n",
    "        target = batch['label'].float().to(device)  \n",
    "        image = batch['image'].to(device)\n",
    "        coords = batch['coords'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image, coords).squeeze()  \n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        predicted = (output > 0.5).float() \n",
    "        correct += (predicted == target).sum().item()\n",
    "        total += target.size(0)\n",
    "\n",
    "    accuracy = 100. * correct / total\n",
    "    return total_loss / len(train_loader), accuracy\n",
    "\n",
    "def validate_classifier(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader):\n",
    "            target = batch['label'].float().to(device)\n",
    "            image = batch['image'].to(device)\n",
    "            coords = batch['coords'].to(device)\n",
    "            output = model(image, coords).squeeze()\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            predicted = (output > 0.5).float()  \n",
    "            correct += (predicted == target).sum().item()\n",
    "            total += target.size(0)\n",
    "            all_preds.append(predicted.cpu().numpy())\n",
    "            all_targets.append(target.cpu().numpy())\n",
    "            \n",
    "        f1 = f1_score(np.concatenate(all_targets), np.concatenate(all_preds))\n",
    "        # print(f'Validation Loss: {total_loss / len(val_loader)}')\n",
    "        # print(f'Validation Accuracy: {100. * correct / total}')\n",
    "        # print(f'Validation F1 Score: {f1}')\n",
    "        return total_loss / len(val_loader), correct / total, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [00:05<00:00, 29.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Train loss: (0.5166283981709541, 73.37301587301587)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 22.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Validation loss: (0.33649000972509385, 0.8428571428571429, 0.8735632183908046)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [00:05<00:00, 29.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Train loss: (0.34242566288272036, 83.88888888888889)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 23.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Validation loss: (0.26953173987567425, 0.8960317460317461, 0.9081990189208129)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [00:05<00:00, 29.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Train loss: (0.28682282557593114, 86.7063492063492)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 22.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Validation loss: (0.23515386022627355, 0.9253968253968254, 0.930780559646539)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [00:05<00:00, 29.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Train loss: (0.2564816809719122, 88.41269841269842)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 21.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Validation loss: (0.21363723538815976, 0.9031746031746032, 0.9168937329700273)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [00:05<00:00, 30.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Train loss: (0.24876164494058753, 88.71031746031746)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 23.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Validation loss: (0.2000930305570364, 0.9373015873015873, 0.9429602888086642)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [00:05<00:00, 28.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Train loss: (0.2412049202602121, 89.38492063492063)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 23.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Validation loss: (0.20517232529819013, 0.9111111111111111, 0.9141104294478528)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [00:05<00:00, 30.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Train loss: (0.23313495629950415, 89.56349206349206)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 22.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Validation loss: (0.21387940356507898, 0.9, 0.9149797570850202)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [00:05<00:00, 31.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Train loss: (0.23250562942857983, 89.76190476190476)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 23.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Validation loss: (0.19509986899793147, 0.9206349206349206, 0.9298737727910238)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [00:05<00:00, 31.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Train loss: (0.22472561004606983, 90.55555555555556)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 23.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Validation loss: (0.22616538871079683, 0.8841269841269841, 0.8841269841269841)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [00:05<00:00, 30.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Train loss: (0.22666252913731563, 90.23809523809524)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 23.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Validation loss: (0.19455335047096015, 0.9134920634920635, 0.9251887439945092)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [00:05<00:00, 30.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Train loss: (0.22592095879814292, 90.27777777777777)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 22.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Validation loss: (0.18829679843038322, 0.926984126984127, 0.9356643356643357)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [00:05<00:00, 29.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Train loss: (0.22544580452804325, 90.05952380952381)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 22.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Validation loss: (0.1907964127138257, 0.9174603174603174, 0.9279778393351801)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [00:05<00:00, 30.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Train loss: (0.21921639979074273, 90.87301587301587)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 23.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Validation loss: (0.17707180129364133, 0.9380952380952381, 0.9441260744985673)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [00:05<00:00, 30.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Train loss: (0.2152173757741723, 90.9920634920635)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 23.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Validation loss: (0.17884824145585299, 0.9357142857142857, 0.9422665716322167)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [00:05<00:00, 29.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Train loss: (0.2158301167095764, 90.67460317460318)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 21.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Validation loss: (0.17349596777930856, 0.9357142857142857, 0.9409190371991247)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 66\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "classifier = ClassifierFeatures_Coords(model, input_dim=latent_dim).to(device) \n",
    "optimizer = optim.Adam(classifier.parameters(), lr=1e-4)\n",
    "criterion_classif = nn.BCELoss()\n",
    "num_epochs = 15\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_classifier(classifier, train_loader_labeled, optimizer,criterion_classif, device)\n",
    "    print(f\"Epoch {epoch} Train loss: {train_loss}\")\n",
    "    val_loss = validate_classifier(classifier, val_loader, criterion_classif, device)\n",
    "    print(f\"Epoch {epoch} Validation loss: {val_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 197/197 [00:06<00:00, 30.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.18376188817892583, 0.9287188442609938, 0.9360125409719253)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_classifier(classifier, test_loader, criterion_classif, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".rob313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
